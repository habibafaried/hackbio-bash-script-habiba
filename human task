#WGS: Whole Genome Sequencing (WGS) Analysis Pipeline for Patient X (human)
#======================================================================================
  #module 00 seting
 #make folder to do the task 
  mkdir human cd human
  # Create a new conda environment with the necessary tools
conda create -n genome_analysis -c bioconda -c conda-forge gatk bwa samtools fastqc -y
  conda activate genome_analysis
#check tools versions 
  # Check the version of GATK
echo "Checking GATK version..."
gatk --version
# Check the version of BWA
echo "Checking BWA version..."
bwa --version
# Check the version of Samtools
echo "Checking Samtools version..."
samtools --version
# Check the version of FastQC
echo "Checking FastQC version..."
fastqc --version
  ==========================================================================================================================
  # model 1 download raw data, check the Quality Control and Preprocessing
mkdir raw_reads && cd raw_reads
nano rawreads.sh
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR315/030/SRR31548730/SRR31548730_1.fastq.gz
bash rawreads.sh
#The first step in processing the raw sequencing data is quality control (QC). We will use fastqc to check the quality of the raw FASTQ file and ensure there are no obvious issues with the sequencing data.
#Create a directory to store QC reports
mkdir qc
# Run FastQC to assess the quality of the raw fastq data
fastqc /data/human_stage_1/SRR31548730_1.fastq.gz -O qc
#Explanation:
#fastqc: This tool assesses the quality of the sequencing data (e.g., base quality, GC content).
#-O qc: This flag specifies the output directory for the results.
#The output will be a report as HTML that you can use to evaluate the raw data quality.

======================================================================================
#model 2 Trimming off Low Quality Reads:
  
  nano trim.sh
 mkdir trimm
input_file="SRR31548730_1.fastq.gz"
output_dir="trim"
  fastp -i SRR31548730_1.fastq.gz -o output_clean.fastq.gz \
      -h fastp_report.html \
      -j fastp_report.json \
      --cut_front \
      --cut_tail \
      --cut_mean_quality 20 \
      --length_required 50

#-i input.fastq.gz: The input raw FASTQ file.
#-o output_clean.fastq.gz: The output cleaned FASTQ file after quality control.
#-h fastp_report.html: Generates an HTML report of the quality control process.
#-j fastp_report.json: Generates a JSON report.
#--cut_front: Trims bases from the 5' (front) end of the read until it meets the quality threshold.
#--cut_tail: Trims bases from the 3' (tail) end of the read until it meets the quality threshold.
#--cut_mean_quality 20: Specifies the mean quality score threshold (in this case, 20). Bases below this score will be trimmed.
#-length_required 50: Discards reads that are shorter than 50 bases after trimming.
cp trim.sh raw_reads && cd raw_reads
bash trim.sh
cp -R raw_reads/trim  
#=================================================================================
  #model 3 Genome Mapping
  # in order to make the assembly we need reference seq to align the genome seq we can download it from NCBI
  # we will use bwa to align seq and make genome mapping 
  #1. Create Reference Genome Index with BWA
#The reference genome (Homo_sapiens_assembly38.fasta) needs to be indexed using BWA before we can align the reads to it.
# Index the reference genome using BWA
bwa index /data/ref/Homo_sapiens_assembly38.fasta
#This will generate the following index files:
#Homo_sapiens_assembly38.fasta.bwt
#Homo_sapiens_assembly38.fasta.pac
#Homo_sapiens_assembly38.fasta.sa
#Homo_sapiens_assembly38.fasta.amb
  nano align.sh 
  #2. Genome Mapping (BWA)
#Now, we will use the BWA to map the single-end reads (output_clean.fastq.gz) against the reference genome (Homo_sapiens_assembly38.fasta).
  # Create a directory to store the mapped reads (BAM files) in the humantask directory
mkdir ~/habiba/humantask/mapped
# Run BWA to align the reads to the reference genome using the correct input file
bwa mem -R '@RG\tID:patientX\tSM:patientX\tPL:ILLUMINA' ~/habiba/humantask/reference/Homo_sapiens_assembly38.fasta ~/habiba/humantask/raw_reads/output_clean.fastq.gz | samtools view -b -o ~/habiba/humantask/mapped/patientX_aligned.bam
bash align.sh
#*.fastq.gz: The correct path to the input file output_clean.fastq.gz in the humantask directory.
#Homo_sapiens_assembly38.fasta: The reference genome path in the humantask/reference directory.
#The output BAM file will be stored as patientX_aligned.bam.
#This will align the reads from output_clean.fastq.gz to the reference genome and store the resulting BAM file in the humantask/mapped directory.
  
 # 3. Sorting the BAM File
#The BAM file generated by BWA needs to be sorted by genomic coordinates. This step is required before proceeding with duplicate marking and variant calling.
# Create a directory for sorted BAM files
mkdir -p ~/habiba/humantask/sorted
# Sort the BAM file by genomic coordinates
gatk SortSam -I ~/habiba/humantask/mapped/patientX_aligned.bam -O ~/habiba/humantask/sorted/patientX_sorted.bam -SORT_ORDER coordinate
#Explanation:
#gatk SortSam: Sorts the BAM file by genomic coordinates.
#Output: A sorted BAM file (patientX_sorted.bam).

  #4. Marking Duplicates
#PCR duplicates are artifacts from the sequencing process that need to be removed to avoid biased variant calling. GATK MarkDuplicates is used to identify and flag these duplicates.
# Create a directory for marked BAM files
mkdir -p ~/habiba/humantask/marked
# Mark duplicates in the sorted BAM file
gatk MarkDuplicates -I ~/habiba/humantask/sorted/patientX_sorted.bam -O ~/habiba/humantask/marked/patientX_marked.bam -M ~/habiba/humantask/marked/patientX_metrics.txt
#Explanation:
#gatk MarkDuplicates: Flags duplicates in the BAM file.
#-M: Generates a metrics file that lists the number of duplicates detected.
#Output: A marked BAM file (patientX_marked.bam) and a metrics file (patientX_metrics.txt).
#=============================================================================================
#5. Building BAM Index
#To speed up processing in later steps, we need to create an index file for the marked BAM file.
# Build the BAM index file for the marked BAM file
gatk BuildBamIndex -I ~/habiba/humantask/marked/patientX_marked.bam
#Explanation:
#gatk BuildBamIndex: Generates an index for the BAM file to allow efficient access in later steps.
#Output: patientX_marked.bam.bai (BAM index file).
  
#======================================================================================================================
  # modal 4 Base Quality Score Recalibration (BQSR)
#To correct for systematic errors in base quality scores, we use GATK BaseRecalibrator. We will use the known indels file (Homo_sapiens_assembly38.known_indels.vcf.gz) for this process.
# Create a directory for BQSR output
mkdir -p ~/habiba/humantask/BQSR
# Run BaseRecalibrator to adjust the base quality scores
gatk BaseRecalibrator -I ~/habiba/humantask/marked/patientX_marked.bam -R /data/ref/Homo_sapiens_assembly38.fasta --known-sites /data/ref/Homo_sapiens_assembly38.known_indels.vcf.gz -O ~/habiba/humantask/BQSR/patientX_recal.table
# Apply the recalibrated scores to the BAM file
gatk ApplyBQSR -I ~/habiba/humantask/marked/patientX_marked.bam -R /data/ref/Homo_sapiens_assembly38.fasta --bqsr-recal-file ~/habiba/humantask/BQSR/patientX_recal.table -O ~/habiba/humantask/BQSR/patientX_recal.bam
  #Explanation:
#gatk BaseRecalibrator: Identifies patterns of base quality score errors and adjusts the scores.
#gatk ApplyBQSR: Applies the recalibrated quality scores to the BAM file.
#Output: The recalibrated BAM file (patientX_recal.bam).
#============================================================================================
# modal 5 Variant Calling Using HaplotypeCaller
#Now, we will use GATK HaplotypeCaller to identify variants (SNPs and indels) from the recalibrated BAM file.
# Create a directory for VCF files (variant call format)
mkdir -p ~/habiba/humantask/VCF
# Run HaplotypeCaller to call variants and output in GVCF format
gatk HaplotypeCaller -I ~/habiba/humantask/BQSR/patientX_recal.bam -R /data/ref/Homo_sapiens_assembly38.fasta -O ~/habiba/humantask/VCF/patientX.g.vcf.gz -ERC GVCF
#Explanation:
#gatk HaplotypeCaller: Identifies SNPs and indels from the recalibrated BAM file and outputs them in GVCF format, which is optimal for multi-sample variant calling.
#Output: The GVCF file (patientX.g.vcf.gz) containing variant calls.
#================================================================================================================
#model 6 Annotating Variants with VEP 
#To interpret the identified variants, we can annotate them using VEP (Variant Effect Predictor). This provides functional information, such as whether the variants affect coding regions or are associated with diseases.
# Annotate the VCF file using VEP (if installed)
vep -i ~/habiba/humantask/VCF/patientX.g.vcf.gz --cache --dir_cache /path/to/vep/cache --output_file ~/habiba/humantask/VCF/patientX_annotated.vcf
#Explanation:
#vep: Variant Effect Predictor annotates the VCF file by providing details about the functional consequences of each variant.
#Output: Annotated VCF file (patientX_annotated.vcf).
#=====================================================================
